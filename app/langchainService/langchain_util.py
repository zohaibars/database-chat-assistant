import operator
import re
from typing import (
    Any,
    Literal,
    Annotated,
    Sequence,
    TypedDict
)
from langchain.pydantic_v1 import BaseModel, Field, validator
from langchain_core.messages import BaseMessage
from langgraph.graph.message import AnyMessage, add_messages
from langgraph.graph import END, StateGraph
from langchain_core.messages import (
    BaseMessage,
    HumanMessage,
    AIMessage,
    SystemMessage,
    ToolMessage
)

class GenerateQuery(BaseModel):
    """Model for inpit arguments of generate query function"""
    user: str = Field(description="The users questions in natural language.")


class ExecutreQuery(BaseModel):
    """Model for input arguments of generate query function"""
    queries: str = Field(description="The query generated by SQL genration LLM")
    
class GetInfo(BaseModel):
    """Model for inpit arguments of get info function"""
    question: str = Field(description="The users questions in natural language with detail.")
    

class TaskState(TypedDict):
    task: str = Field(description="Task that requires sql query")
    strategy: str = Field(description="Strategy required to construct an SQL query.")
    sql_query: str = Field(description="SQL query that can achive the task")
    evaluation: str = Field(description="Evaluating the sql queries based on task and data retrieved")
    max_revisions: int = Field(description="Max revisions possible")
    revision_number: int = Field(description="Current Revision")
    dialect: str = Field(description="Name of the SQL dialect to query from")
    table_info: str = Field(description="Relevant tables information: create table, sample rows, descriptions")
    examples: str = Field(description="Relevant examples")
    step: str = Field(description="Current step the SQL process is on")
    final_response: str = Field(description="Final response by after all the revisions")
    

class AssistantState(TypedDict):
    chat_history: Annotated[list[AnyMessage], operator.add]
    
class AssistantAgent:
    def __init__(
        self,
        llm,
        checkpointer,
        tools=[],
        system=""
    ):
        self.llm = llm
        self.system = system
        graph = StateGraph(AssistantState)
        graph.add_node("llm", self.ask_llm)
        graph.add_node("action", self.take_actions)
        graph.add_conditional_edges(
            "llm",
            self.check_tool_calls,
            {True: "action", False: END}
        )
        graph.add_edge("action", "llm")
        graph.set_entry_point("llm")
        self.graph = graph.compile(checkpointer=checkpointer)
        self.tools = {t.name: t for t in tools}
        self.model = llm.bind_tools(tools)
    
    def check_tool_calls(self, state: AssistantState):
        last_message = state["chat_history"][-1]
        action_re = re.compile('^Action: (\w+): (.*)$') 
        actions = [
            action_re.match(action) for action in
            last_message.split("\n") if action_re.match(action)
        ]
        if actions:
            print(True)
            return True
        else:
            print(False)
            return False
        
    def take_actions(self, state: AssistantState):
        return 0 
    
    def ask_llm(self, state: AssistantState):
        # messages = state["chat_history"]
        if self.system:
            messages = [
                SystemMessage(
                    content=self.system
                )
            ] + messages
        response = self.llm.invoke(messages)
        return {"chat_history": response}
    