{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To handle event loop error by nesting it onto the runtime loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializng logger and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SQLDatabase\n",
    "from llama_index.readers.wikipedia import WikipediaReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a test sql database using sqllite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    inspect,\n",
    "    select,\n",
    "    column,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: thenlper/gte-base\n",
      "Load pretrained SentenceTransformer: thenlper/gte-base\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.groq import Groq\n",
    "api_key=\"\"\n",
    "llm = Groq(model=\"llama3-8b-8192\",\n",
    "    api_key=api_key,\n",
    "    temperature=0.5\n",
    ")\n",
    "embediing_model = HuggingFaceEmbedding(model_name='thenlper/gte-base')\n",
    "Settings.llm = llm\n",
    "Settings.embed_model=embediing_model\n",
    "engine = create_engine(\"sqlite:///mydatabase.db\", future=True)\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a table in the Initialized database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table('city_stats', MetaData(), Column('city_name', String(length=16), table=<city_stats>, primary_key=True, nullable=False), Column('population', Integer(), table=<city_stats>), Column('country', String(length=16), table=<city_stats>, nullable=False), schema=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_obj.tables.keys()\n",
    "city_stats_table = metadata_obj.tables['city_stats']\n",
    "city_stats_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "rows = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
    "    {\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading more city data form wikipidea and adding to db. 50 famous cities of asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# few names causing issue therefore not used\n",
    "famous_asian_cities = [\n",
    "    \"Tokyo\",\n",
    "    \"Beijing\",\n",
    "    \"Shanghai\",\n",
    "    \"Seoul\",\n",
    "    \"Mumbai\",\n",
    "    \"Delhi\",\n",
    "    \"Bangkok\",\n",
    "    \"Singapore\",\n",
    "    # \"Hong Kong\",\n",
    "    \"Jakarta\",\n",
    "    \"Kuala Lumpur\",\n",
    "    # \"Manila\",\n",
    "    \"Hanoi\",\n",
    "    \"Ho Chi Minh City\",\n",
    "    \"Dubai\",\n",
    "    \"Istanbul\",\n",
    "    \"Jerusalem\",\n",
    "    \"Kyoto\",\n",
    "    \"Osaka\",\n",
    "    # \"Chengdu\",\n",
    "    \"Taipei\",\n",
    "    # \"Xian\",\n",
    "    \"Kathmandu\",\n",
    "    \"Colombo\",\n",
    "    \"Dhaka\",\n",
    "    \"Yangon\",\n",
    "    \"Ulaanbaatar\",\n",
    "    \"Riyadh\",\n",
    "    \"Tehran\",\n",
    "    \"Baghdad\",\n",
    "    \"Beirut\",\n",
    "    # \"Amman\",\n",
    "    \"Baku\",\n",
    "    \"Tashkent\",\n",
    "    # \"Almaty\",\n",
    "    \"Phnom Penh\",\n",
    "    \"Vientiane\",\n",
    "    # \"Male\",\n",
    "    \"Thimphu\",\n",
    "    \"Bandar Seri Begawan\",\n",
    "    # \"Macau\",\n",
    "    \"George Town\",\n",
    "    \"Jeju City\",\n",
    "    # \"Busan\",\n",
    "    \"Gyeongju\",\n",
    "    \"Samarkand\",\n",
    "    \"Bukhara\"\n",
    "]\n",
    "wiki_docs = WikipediaReader().load_data(pages=famous_asian_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a indexing object for table schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core import SQLDatabase, VectorStoreIndex\n",
    "sql_database = SQLDatabase(engine)\n",
    "\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = []\n",
    "for table_name in metadata_obj.tables.keys():\n",
    "    table_schema_objs.append(SQLTableSchema(table_name=table_name))\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FnComponent(partial_dict={}, fn=<function get_table_context_str at 0x71d156d31750>, async_fn=None, output_key='output')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from llama_index.core.retrievers import SQLRetriever\n",
    "from typing import List\n",
    "from llama_index.core.query_pipeline import FnComponent\n",
    "\n",
    "sql_retriever = SQLRetriever(sql_database)\n",
    "\n",
    "def get_table_context_str(table_schema_objs: List[SQLTableSchema]):\n",
    "    \"\"\"Get table context string.\"\"\"\n",
    "    context_strs = []\n",
    "    for table_schema_obj in table_schema_objs:\n",
    "        table_info = sql_database.get_single_table_info(\n",
    "            table_schema_obj.table_name\n",
    "        )\n",
    "        if table_schema_obj.context_str:\n",
    "            table_opt_context = \" The table description is: \"\n",
    "            table_opt_context += table_schema_obj.context_str\n",
    "            table_info += table_opt_context\n",
    "\n",
    "        context_strs.append(table_info)\n",
    "    return \"\\n\\n\".join(context_strs)\n",
    "\n",
    "\n",
    "table_parser_component = FnComponent(fn=get_table_context_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use tables listed below.\n",
      "{schema}\n",
      "\n",
      "Question: {query_str}\n",
      "SQLQuery: \n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.prompts.default_prompts import DEFAULT_TEXT_TO_SQL_PROMPT\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_pipeline import FnComponent\n",
    "from llama_index.core.llms import ChatResponse\n",
    "\n",
    "\n",
    "def parse_response_to_sql(response: ChatResponse) -> str:\n",
    "    \"\"\"Parse response to SQL.\"\"\"\n",
    "    response = response.message.content\n",
    "    sql_query_start = response.find(\"SQLQuery:\")\n",
    "    if sql_query_start != -1:\n",
    "        response = response[sql_query_start:]\n",
    "        # TODO: move to removeprefix after Python 3.9+\n",
    "        if response.startswith(\"SQLQuery:\"):\n",
    "            response = response[len(\"SQLQuery:\") :]\n",
    "    sql_result_start = response.find(\"SQLResult:\")\n",
    "    if sql_result_start != -1:\n",
    "        response = response[:sql_result_start]\n",
    "    return response.strip().strip(\"```\").strip()\n",
    "\n",
    "\n",
    "sql_parser_component = FnComponent(fn=parse_response_to_sql)\n",
    "\n",
    "text2sql_prompt = DEFAULT_TEXT_TO_SQL_PROMPT.partial_format(\n",
    "    dialect=engine.dialect.name\n",
    ")\n",
    "print(text2sql_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"SQL: {sql_query}\\n\"\n",
    "    \"SQL Response: {context_str}\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "response_synthesis_prompt = PromptTemplate(\n",
    "    response_synthesis_prompt_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    "    CustomQueryComponent,\n",
    ")\n",
    "\n",
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": InputComponent(),\n",
    "        \"table_retriever\": obj_retriever,\n",
    "        \"table_output_parser\": table_parser_component,\n",
    "        \"text2sql_prompt\": text2sql_prompt,\n",
    "        \"text2sql_llm\": llm,\n",
    "        \"sql_output_parser\": sql_parser_component,\n",
    "        \"sql_retriever\": sql_retriever,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"response_synthesis_llm\": llm,\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp.add_chain([\"input\", \"table_retriever\", \"table_output_parser\"])\n",
    "qp.add_link(\"input\", \"text2sql_prompt\", dest_key=\"query_str\")\n",
    "qp.add_link(\"table_output_parser\", \"text2sql_prompt\", dest_key=\"schema\")\n",
    "qp.add_chain(\n",
    "    [\"text2sql_prompt\", \"text2sql_llm\", \"sql_output_parser\", \"sql_retriever\"]\n",
    ")\n",
    "qp.add_link(\n",
    "    \"sql_output_parser\", \"response_synthesis_prompt\", dest_key=\"sql_query\"\n",
    ")\n",
    "qp.add_link(\n",
    "    \"sql_retriever\", \"response_synthesis_prompt\", dest_key=\"context_str\"\n",
    ")\n",
    "qp.add_link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\")\n",
    "qp.add_link(\"response_synthesis_prompt\", \"response_synthesis_llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query: Which countries are each city from??\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module table_retriever with input: \n",
      "input: Which countries are each city from??\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module table_output_parser with input: \n",
      "table_schema_objs: [SQLTableSchema(table_name='city_stats', context_str=None)]\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module text2sql_prompt with input: \n",
      "query_str: Which countries are each city from??\n",
      "schema: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module text2sql_llm with input: \n",
      "messages: Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;2;155;135;227m> Running module sql_output_parser with input: \n",
      "response: assistant: Question: Which countries are each city from??\n",
      "SQLQuery: SELECT city_stats.country, city_stats.city_name FROM city_stats;\n",
      "SQLResult: country    city_name\n",
      "-------------------------\n",
      "SQLResult...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_retriever with input: \n",
      "input: SELECT city_stats.country, city_stats.city_name FROM city_stats;\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: Which countries are each city from??\n",
      "sql_query: SELECT city_stats.country, city_stats.city_name FROM city_stats;\n",
      "context_str: [NodeWithScore(node=TextNode(id_='380c13ee-4b31-4dd2-9fc5-0961f4b9ab1f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"[('Canada'...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_llm with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: Which countries are each city from??\n",
      "SQL: SELECT city_stats.country, city_stats.city_name FROM city_stats;\n",
      "SQL Response: [...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "assistant: Here is a synthesized response based on the SQL query results:\n",
      "\n",
      "The cities mentioned are from the following countries:\n",
      "\n",
      "* Toronto is from Canada\n",
      "* Tokyo is from Japan\n",
      "* Berlin is from Germany\n",
      "\n",
      "Let me know if you'd like me to help with anything else!\n"
     ]
    }
   ],
   "source": [
    "response = qp.run(\n",
    "    query=\"Which countries are each city from??\"\n",
    ")\n",
    "print(str(response))\n",
    "# city_stats_table.columns.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
